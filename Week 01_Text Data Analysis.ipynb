{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Features of Text Data Analytics\n",
    "\n",
    "## 1. sequential data\n",
    "* Dependency: 이전에 나온 말이 이후에 나올 말에 영향\n",
    "* 어순이 중요\n",
    "## 2. discrete variable\n",
    "* Dimension: number of variables, number of words\n",
    "* Many dimensions in Text\n",
    "## 3. complicated Structure\n",
    "* Recursion(재귀): 하나의 구조 안에 동일한 구조가 포함 (나는 철수가 영희를 사랑한다는 것을 알고 있다.)\n",
    "## 4. ambiguity\n",
    "* 동음이의어, 애매한 문장 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Text Data\n",
    "\n",
    "* File, Database\n",
    "* Web Scraping\n",
    "* Speech to Text\n",
    "* OCR (Optical Character Recognition)\n",
    "\n",
    "**corpus(말뭉치)**: gathered text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "1. 불필요한 표현 삭제\n",
    "2. Normalization: 분석에 편리한 형태로 변환\n",
    "    * 토큰화 (tokenization)\n",
    "    * lemmatization / stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 토큰화 (tokenization)\n",
    "* token: 텍스트 분석의 단위 (단어, 형태소 등)\n",
    "* 형태소: 의미가 있는 최소 단위\n",
    "* 단어 분리 (word segmentation): 띄어쓰기가 없는 Mandarin, Japanese, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) lemmatization / stemming\n",
    "* lemmatization: 사전에 등재된 형태(lemma)로 바꾸는 것\n",
    "* stemming: 휴리스틱을 이용해 어간(stem)을 분리해내는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing Data\n",
    "1. 단어 문서 행렬 (term document matrix)\n",
    "    * 어순을 무시\n",
    "    * document 별로 단어의 frequency table 만들기\n",
    "2. tokens를 출현한 순서대로 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Text Data Analytics\n",
    "\n",
    "## 1. Text Classification\n",
    "* Supervised Learning\n",
    "* document를 미리 정해진 Type으로 분류하는 것\n",
    "* 가장 널리 사용됨\n",
    "\n",
    "## 2. Sentiment Analysis\n",
    "* a.k.a. Option Mining\n",
    "* Positive OR Negative Attitudes\n",
    "* Emotion Analysis: 기쁨, 슬픔, 화남, 우울, 신남 등으로 나누는 것\n",
    "\n",
    "## 3. Named Entity Recognition\n",
    "* 개체명 인식\n",
    "* 사람, 장소, 단체 등 특정한 종류의 이름(Named Entity)를 인식\n",
    "* Chatbot에서 특정한 상품명을 인식할 필요가 있을 때 사용\n",
    "* Named Entity가 여러 단어로 되어 있을 수 있음\n",
    "* Named Entity는 계속해서 새롭게 생기기 때문에 사전으로 만들기 어려움\n",
    "\n",
    "## 4. Relationship Extraction\n",
    "* 텍스트에서 두 개체 사이의 관계를 추출\n",
    "* e.g., **Billy**, **Austin**: City of Birth\n",
    "\n",
    "## 5. Intent Detection & Slot Filling\n",
    "* 주로 Chatbot에 사용됨\n",
    "* 사용자의 의도(intent)를 정해진 유형 중의 하나로 분류하고 (via Text Classification)\n",
    "* 정해진 정보의 Slot에 채움\n",
    "* e.g., **What flights are available from Austin to Dallas on Thursday morning?**\n",
    "    * **Intent**: flight info\n",
    "    * **Slots**:\n",
    "        * from_city: Austin\n",
    "        * to_city: Dallas\n",
    "        * depart_date: Thursday\n",
    "        * depart_time: morning\n",
    "\n",
    "## 6. Summarization\n",
    "* Type 1. 중요한 문장 하나를 추출하는 방법\n",
    "* Type 2. 새로운 문장 하나를 만드는 방법 (via Supervised Learning)\n",
    "* 정답이 없기 때문에 평가하기가 어려움\n",
    "\n",
    "## 7. Machine Translation\n",
    "* Google Translator\n",
    "* 병렬 말뭉치가 필요\n",
    "\n",
    "## 8. Question Answering\n",
    "* 질문(Question)에 대한 답을 주어진 텍스트(Document) 내에서 찾음\n",
    "\n",
    "## 9. Common Sense Reasoning\n",
    "* 주어진 텍스트에 이어질 내용이나 빈 칸에 들어갈 내용을 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to deal with lack of raw data\n",
    "\n",
    "1. 데이터를 더 많이 모은다.\n",
    "2. Unsupervised Learning으로 패턴을 추출 → 추출한 패턴으로 Supervised Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
